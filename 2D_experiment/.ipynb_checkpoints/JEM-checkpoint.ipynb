{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joint Energy-based Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan:\n",
    "1. Generate the data\n",
    "2. Build classifier and criterion as CE\n",
    "3. Implement alg 1: keep track of the loses\n",
    "4. Refine to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import distributions\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from utils import ClassifierNN, train_network, refine_sample_exact, save_model_info, load_model_info, refine_sample, criterion\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(40)\n",
    "random.seed(40)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the data\n",
    "\n",
    "# M1 data: my label 0 data\n",
    "mean1 = np.array([0, 0])\n",
    "cov1 = np.array([[3, 0], [0, 3]])\n",
    "M1 = distributions.multivariate_normal.MultivariateNormal(loc=torch.from_numpy(mean1).float(), \n",
    "                                                         covariance_matrix=torch.from_numpy(cov1).float())\n",
    "\n",
    "# M2 data: my label 1 data\n",
    "mean2 = np.array([3, 3])\n",
    "cov2 = np.array([[1, 0], [0, 1]])\n",
    "M2 = distributions.multivariate_normal.MultivariateNormal(loc=torch.from_numpy(mean2).float(), \n",
    "                                                         covariance_matrix=torch.from_numpy(cov2).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visulize\n",
    "m1_samples = M1.sample([1000])\n",
    "m2_samples = M2.sample([1000])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.scatter(m1_samples[:,0], m1_samples[:,1], label='M1', color='r', marker='.', alpha=0.2)\n",
    "ax.scatter(m2_samples[:,0], m2_samples[:,1], label='M2', color='g', marker='.', alpha=0.2)\n",
    "ax.set_xlim([-10, 10])\n",
    "ax.set_ylim([-10, 10])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle(loader):\n",
    "    while True:\n",
    "        for data in loader:\n",
    "            yield data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 2000\n",
    "batch_size = 256\n",
    "X_train = torch.vstack([M1.sample([nsamples]).float(), M2.sample([nsamples]).float() ] )\n",
    "y_train = torch.hstack([torch.zeros([nsamples]).long(), torch.ones([nsamples]).long() ] )\n",
    "\n",
    "# nsamples = 2000\n",
    "X_test = torch.vstack([M1.sample([nsamples]).float(), M2.sample([nsamples]).float() ] )\n",
    "y_test = torch.hstack([torch.zeros([nsamples]).long(), torch.ones([nsamples]).long() ] )\n",
    "\n",
    "train_dataset_labeled = TensorDataset(X_train, y_train) # transform to torch tensor\n",
    "train_dataloader_labeled = DataLoader(train_dataset_labeled, batch_size=batch_size, shuffle=True) # train data with labels\n",
    "train_dataloader_labeled = cycle(train_dataloader_labeled)\n",
    "\n",
    "train_dataset = TensorDataset(X_train) # transform to torch tensor\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True) # train data no labels\n",
    "\n",
    "\n",
    "test_dataset = TensorDataset(X_test.float(), y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_freq = 10\n",
    "n_epochs = 2000\n",
    "sgld_lr = 1.0\n",
    "sgld_std = 0.01\n",
    "buffer_size = 10000\n",
    "reinit_freq = 0.05\n",
    "n_steps = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_random(bs):\n",
    "    return torch.FloatTensor(bs, 2).uniform_(-1, 1)\n",
    "\n",
    "def get_sample_q( device):\n",
    "    def sample_p_0(replay_buffer, bs, y=None):\n",
    "        if len(replay_buffer) == 0:\n",
    "            return init_random(bs), []\n",
    "        buffer_size = len(replay_buffer) if y is None else len(replay_buffer) // n_classes\n",
    "        inds = torch.randint(0, buffer_size, (bs,))\n",
    "        # if cond, convert inds to class conditional inds\n",
    "        if y is not None:\n",
    "            inds = y.cpu() * buffer_size + inds\n",
    "            assert not uncond, \"Can't drawn conditional samples without giving me y\"\n",
    "        buffer_samples = replay_buffer[inds]\n",
    "        random_samples = init_random(bs)\n",
    "        choose_random = (torch.rand(bs) < reinit_freq).float()[:, None]\n",
    "        samples = choose_random * random_samples + (1 - choose_random) * buffer_samples\n",
    "        return samples.to(device), inds\n",
    "\n",
    "    def sample_q(f, replay_buffer, y=None, n_steps=n_steps):\n",
    "        \"\"\"this func takes in replay_buffer now so we have the option to sample from\n",
    "        scratch (i.e. replay_buffer==[]).  See test_wrn_ebm.py for example.\n",
    "        \"\"\"\n",
    "        f.eval()\n",
    "        # get batch size\n",
    "        bs = batch_size if y is None else y.size(0)\n",
    "        # generate initial samples and buffer inds of those samples (if buffer is used)\n",
    "        init_sample, buffer_inds = sample_p_0(replay_buffer, bs=bs, y=y)\n",
    "        x_k = torch.autograd.Variable(init_sample, requires_grad=True)\n",
    "        # sgld\n",
    "        for k in range(n_steps):\n",
    "            f_prime = torch.autograd.grad(f(x_k).sum(), [x_k], retain_graph=True)[0]\n",
    "            x_k.data += sgld_lr * f_prime + sgld_std * torch.randn_like(x_k)\n",
    "        f.train()\n",
    "        final_samples = x_k.detach()\n",
    "        # update replay buffer\n",
    "        if len(replay_buffer) > 0:\n",
    "            replay_buffer[buffer_inds] = final_samples.cpu()\n",
    "        return final_samples\n",
    "    return sample_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_q = get_sample_q(device)\n",
    "replay_buffer = init_random(buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ClassifierNN(2, 64, 2).to(device) # outputs two data\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(f.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10\n",
      "Train l_p_x: 0.0036929426714777946 | Test l_p_x: 0.003877938725054264\n",
      "Train l_p_y_given_x: 0.05646664071083069 | Test l_p_y_given_x: 0.05917524576187134\n",
      "Train acc: 0.78575 | Test acc: 0.78575\n",
      "Epoch: 20\n",
      "Train l_p_x: 0.004783844109624624 | Test l_p_x: 0.005604809150099754\n",
      "Train l_p_y_given_x: 0.0786927089691162 | Test l_p_y_given_x: 0.08067787647247314\n",
      "Train acc: 0.7845 | Test acc: 0.784\n",
      "Epoch: 30\n",
      "Train l_p_x: 0.005072008818387985 | Test l_p_x: 0.005254222080111504\n",
      "Train l_p_y_given_x: 0.08326998090744019 | Test l_p_y_given_x: 0.08274781465530395\n",
      "Train acc: 0.78225 | Test acc: 0.78225\n",
      "Epoch: 40\n",
      "Train l_p_x: 0.004861310124397278 | Test l_p_x: 0.004646786954253912\n",
      "Train l_p_y_given_x: 0.0746700348854065 | Test l_p_y_given_x: 0.07272423362731933\n",
      "Train acc: 0.77725 | Test acc: 0.7765\n",
      "Epoch: 50\n",
      "Train l_p_x: 0.0038227401673793793 | Test l_p_x: 0.0038105782587081194\n",
      "Train l_p_y_given_x: 0.06135387635231018 | Test l_p_y_given_x: 0.06179859089851379\n",
      "Train acc: 0.77225 | Test acc: 0.772\n",
      "Epoch: 60\n",
      "Train l_p_x: 0.003336309688165784 | Test l_p_x: 0.0029643296729773283\n",
      "Train l_p_y_given_x: 0.050283972024917606 | Test l_p_y_given_x: 0.05015833401679993\n",
      "Train acc: 0.7665 | Test acc: 0.76625\n",
      "Epoch: 70\n",
      "Train l_p_x: 0.0021583649795502424 | Test l_p_x: 0.0022169447038322687\n",
      "Train l_p_y_given_x: 0.03671195435523987 | Test l_p_y_given_x: 0.03631869626045227\n",
      "Train acc: 0.7615 | Test acc: 0.76125\n",
      "Epoch: 80\n",
      "Train l_p_x: 0.0016543336678296328 | Test l_p_x: 0.0016325842589139938\n",
      "Train l_p_y_given_x: 0.027182283878326417 | Test l_p_y_given_x: 0.02534968113899231\n",
      "Train acc: 0.7585 | Test acc: 0.7585\n",
      "Epoch: 90\n",
      "Train l_p_x: 0.0008718348108232021 | Test l_p_x: 0.0008349191630259156\n",
      "Train l_p_y_given_x: 0.018214848697185516 | Test l_p_y_given_x: 0.01859152191877365\n",
      "Train acc: 0.75625 | Test acc: 0.75625\n",
      "Epoch: 100\n",
      "Train l_p_x: 0.0008354951278306544 | Test l_p_x: 0.0008033756748773158\n",
      "Train l_p_y_given_x: 0.01347162240743637 | Test l_p_y_given_x: 0.012648087978363037\n",
      "Train acc: 0.755 | Test acc: 0.755\n",
      "Epoch: 110\n",
      "Train l_p_x: 0.0004592353361658752 | Test l_p_x: 0.0006448833155445755\n",
      "Train l_p_y_given_x: 0.008724120676517486 | Test l_p_y_given_x: 0.008260841727256775\n",
      "Train acc: 0.75525 | Test acc: 0.75525\n",
      "Epoch: 120\n",
      "Train l_p_x: 0.0002940456324722618 | Test l_p_x: 0.0003360277914907783\n",
      "Train l_p_y_given_x: 0.005706332266330719 | Test l_p_y_given_x: 0.005630929291248321\n",
      "Train acc: 0.7555 | Test acc: 0.75575\n",
      "Epoch: 130\n",
      "Train l_p_x: 0.00024779303930699825 | Test l_p_x: 0.00030856343801133335\n",
      "Train l_p_y_given_x: 0.0037616439908742904 | Test l_p_y_given_x: 0.004096393778920173\n",
      "Train acc: 0.75675 | Test acc: 0.75675\n",
      "Epoch: 140\n",
      "Train l_p_x: 0.00012617118773050606 | Test l_p_x: 6.244298856472597e-05\n",
      "Train l_p_y_given_x: 0.002610445946455002 | Test l_p_y_given_x: 0.0024040045887231826\n",
      "Train acc: 0.75825 | Test acc: 0.7585\n",
      "Epoch: 150\n",
      "Train l_p_x: 0.00014511431800201535 | Test l_p_x: 0.00010770267545012757\n",
      "Train l_p_y_given_x: 0.0016753705590963363 | Test l_p_y_given_x: 0.0016807484924793244\n",
      "Train acc: 0.75975 | Test acc: 0.75975\n",
      "Epoch: 160\n",
      "Train l_p_x: 6.710268644383177e-05 | Test l_p_x: 6.813229992985725e-05\n",
      "Train l_p_y_given_x: 0.0010628573298454285 | Test l_p_y_given_x: 0.0010611416697502137\n",
      "Train acc: 0.762 | Test acc: 0.76225\n",
      "Epoch: 170\n",
      "Train l_p_x: 3.542955528246239e-05 | Test l_p_x: 6.271870370255783e-05\n",
      "Train l_p_y_given_x: 0.0007437540590763092 | Test l_p_y_given_x: 0.0008965426981449127\n",
      "Train acc: 0.76525 | Test acc: 0.7655\n",
      "Epoch: 180\n",
      "Train l_p_x: 4.1187169699696824e-05 | Test l_p_x: 3.4750268241623417e-05\n",
      "Train l_p_y_given_x: 0.00024033676087856294 | Test l_p_y_given_x: 0.00035442058742046355\n",
      "Train acc: 0.76775 | Test acc: 0.76775\n",
      "Epoch: 190\n",
      "Train l_p_x: 1.698641608527396e-05 | Test l_p_x: 2.262517909912276e-06\n",
      "Train l_p_y_given_x: 0.0002974226325750351 | Test l_p_y_given_x: 0.0001553272306919098\n",
      "Train acc: 0.77075 | Test acc: 0.771\n",
      "Epoch: 200\n",
      "Train l_p_x: 1.5560717656626366e-05 | Test l_p_x: -8.893401172826998e-06\n",
      "Train l_p_y_given_x: 0.0002343270778656006 | Test l_p_y_given_x: 7.72542655467987e-05\n",
      "Train acc: 0.7735 | Test acc: 0.77375\n",
      "Epoch: 210\n",
      "Train l_p_x: 1.3804466107103508e-05 | Test l_p_x: -4.014969192667195e-07\n",
      "Train l_p_y_given_x: 4.679235816001892e-05 | Test l_p_y_given_x: -3.366518020629883e-05\n",
      "Train acc: 0.77425 | Test acc: 0.77425\n",
      "Epoch: 220\n",
      "Train l_p_x: -8.143857485265471e-06 | Test l_p_x: -1.914873791974969e-06\n",
      "Train l_p_y_given_x: -4.1148290038108825e-05 | Test l_p_y_given_x: -2.2584840655326844e-05\n",
      "Train acc: 0.776 | Test acc: 0.776\n",
      "Epoch: 230\n",
      "Train l_p_x: -8.638560757390223e-06 | Test l_p_x: -9.286329259339254e-06\n",
      "Train l_p_y_given_x: -6.854417920112609e-05 | Test l_p_y_given_x: -8.391325175762177e-05\n",
      "Train acc: 0.77725 | Test acc: 0.7775\n",
      "Epoch: 240\n",
      "Train l_p_x: -1.0109559298143722e-05 | Test l_p_x: -1.3439670510706492e-05\n",
      "Train l_p_y_given_x: -0.000141549676656723 | Test l_p_y_given_x: -0.00010723726451396942\n",
      "Train acc: 0.77875 | Test acc: 0.7785\n",
      "Epoch: 250\n",
      "Train l_p_x: -1.1818260645668488e-05 | Test l_p_x: -1.2048974895151332e-05\n",
      "Train l_p_y_given_x: -0.0001693088561296463 | Test l_p_y_given_x: -0.00016857980191707612\n",
      "Train acc: 0.7795 | Test acc: 0.7795\n",
      "Epoch: 260\n",
      "Train l_p_x: -1.470428742322838e-05 | Test l_p_x: -1.03131533251144e-05\n",
      "Train l_p_y_given_x: -0.0001972243934869766 | Test l_p_y_given_x: -0.0001884089708328247\n",
      "Train acc: 0.782 | Test acc: 0.78225\n",
      "Epoch: 270\n",
      "Train l_p_x: -1.9454957509879023e-05 | Test l_p_x: -2.5249675672966987e-05\n",
      "Train l_p_y_given_x: -0.0002144487202167511 | Test l_p_y_given_x: -0.00022645165026187897\n",
      "Train acc: 0.78375 | Test acc: 0.7835\n",
      "Epoch: 280\n",
      "Train l_p_x: -1.6308158592437394e-05 | Test l_p_x: -2.0021931049996056e-05\n",
      "Train l_p_y_given_x: -0.00025264863669872284 | Test l_p_y_given_x: -0.00025855666399002074\n",
      "Train acc: 0.78525 | Test acc: 0.7855\n",
      "Epoch: 290\n",
      "Train l_p_x: -1.3662606761499774e-05 | Test l_p_x: -1.8819198885466903e-05\n",
      "Train l_p_y_given_x: -0.00028559525310993197 | Test l_p_y_given_x: -0.00028329811990261076\n",
      "Train acc: 0.7865 | Test acc: 0.7865\n",
      "Epoch: 300\n",
      "Train l_p_x: -2.4614751964691095e-05 | Test l_p_x: -1.578046430950053e-05\n",
      "Train l_p_y_given_x: -0.0003234235495328903 | Test l_p_y_given_x: -0.000320115327835083\n",
      "Train acc: 0.78775 | Test acc: 0.78775\n",
      "Epoch: 310\n",
      "Train l_p_x: -2.241332913399674e-05 | Test l_p_x: -2.139516254828777e-05\n",
      "Train l_p_y_given_x: -0.0003492245227098465 | Test l_p_y_given_x: -0.00035187435150146483\n",
      "Train acc: 0.79 | Test acc: 0.7905\n",
      "Epoch: 320\n",
      "Train l_p_x: -1.4098630344960839e-05 | Test l_p_x: -2.245856921945233e-05\n",
      "Train l_p_y_given_x: -0.00038652467727661133 | Test l_p_y_given_x: -0.0003967602103948593\n",
      "Train acc: 0.79225 | Test acc: 0.79225\n",
      "Epoch: 330\n",
      "Train l_p_x: -2.064569343929179e-05 | Test l_p_x: -2.078215948131401e-05\n",
      "Train l_p_y_given_x: -0.00042383697628974916 | Test l_p_y_given_x: -0.00042710214853286743\n",
      "Train acc: 0.794 | Test acc: 0.794\n",
      "Epoch: 340\n",
      "Train l_p_x: -2.8727010430884548e-05 | Test l_p_x: -3.256845593568869e-05\n",
      "Train l_p_y_given_x: -0.00046243798732757566 | Test l_p_y_given_x: -0.00046545864641666415\n",
      "Train acc: 0.79625 | Test acc: 0.79625\n",
      "Epoch: 350\n",
      "Train l_p_x: -2.8277010642341338e-05 | Test l_p_x: -3.5860033676726744e-05\n",
      "Train l_p_y_given_x: -0.0004943508505821228 | Test l_p_y_given_x: -0.000503943458199501\n",
      "Train acc: 0.7985 | Test acc: 0.7985\n",
      "Epoch: 360\n",
      "Train l_p_x: -3.640471550170332e-05 | Test l_p_x: -2.90772040898446e-05\n",
      "Train l_p_y_given_x: -0.0005353534668684006 | Test l_p_y_given_x: -0.0005299818962812424\n",
      "Train acc: 0.80125 | Test acc: 0.80125\n",
      "Epoch: 370\n",
      "Train l_p_x: -3.434239624766633e-05 | Test l_p_x: -3.931647734134458e-05\n",
      "Train l_p_y_given_x: -0.0005611476451158524 | Test l_p_y_given_x: -0.0005668472051620484\n",
      "Train acc: 0.802 | Test acc: 0.802\n",
      "Epoch: 380\n",
      "Train l_p_x: -4.364364212960936e-05 | Test l_p_x: -3.9009824831737205e-05\n",
      "Train l_p_y_given_x: -0.0006067990064620971 | Test l_p_y_given_x: -0.0006106494069099426\n",
      "Train acc: 0.805 | Test acc: 0.80525\n",
      "Epoch: 390\n",
      "Train l_p_x: -4.186122168903239e-05 | Test l_p_x: -4.559402441373095e-05\n",
      "Train l_p_y_given_x: -0.0006339084357023239 | Test l_p_y_given_x: -0.0006448483020067214\n",
      "Train acc: 0.80725 | Test acc: 0.80775\n",
      "Epoch: 400\n",
      "Train l_p_x: -3.506039138301276e-05 | Test l_p_x: -4.355825512902811e-05\n",
      "Train l_p_y_given_x: -0.0006765029579401016 | Test l_p_y_given_x: -0.0006852341294288635\n",
      "Train acc: 0.81025 | Test acc: 0.81025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 410\n",
      "Train l_p_x: -4.308894494897686e-05 | Test l_p_x: -5.175680053071119e-05\n",
      "Train l_p_y_given_x: -0.0007156862020492554 | Test l_p_y_given_x: -0.0007244772911071777\n",
      "Train acc: 0.812 | Test acc: 0.812\n",
      "Epoch: 420\n",
      "Train l_p_x: -5.337658876669593e-05 | Test l_p_x: -5.115330350236036e-05\n",
      "Train l_p_y_given_x: -0.00075348399579525 | Test l_p_y_given_x: -0.0007556561827659607\n",
      "Train acc: 0.81475 | Test acc: 0.81475\n",
      "Epoch: 430\n",
      "Train l_p_x: -4.458174225874245e-05 | Test l_p_x: -4.210424594930373e-05\n",
      "Train l_p_y_given_x: -0.0008002121150493622 | Test l_p_y_given_x: -0.0007992041856050491\n",
      "Train acc: 0.81675 | Test acc: 0.81675\n",
      "Epoch: 440\n",
      "Train l_p_x: -4.4571745092980564e-05 | Test l_p_x: -5.419819353846833e-05\n",
      "Train l_p_y_given_x: -0.0008323370218276978 | Test l_p_y_given_x: -0.0008415718376636505\n",
      "Train acc: 0.819 | Test acc: 0.81925\n",
      "Epoch: 450\n",
      "Train l_p_x: -5.5764052376616746e-05 | Test l_p_x: -5.089904516353272e-05\n",
      "Train l_p_y_given_x: -0.0008789912462234497 | Test l_p_y_given_x: -0.0008853169530630111\n",
      "Train acc: 0.8205 | Test acc: 0.8205\n",
      "Epoch: 460\n",
      "Train l_p_x: -6.112481787567958e-05 | Test l_p_x: -5.552287620957941e-05\n",
      "Train l_p_y_given_x: -0.0009031494706869125 | Test l_p_y_given_x: -0.00090814508497715\n",
      "Train acc: 0.8245 | Test acc: 0.82525\n",
      "Epoch: 470\n",
      "Train l_p_x: -7.465972157660872e-05 | Test l_p_x: -7.742344314465299e-05\n",
      "Train l_p_y_given_x: -0.0009377129673957825 | Test l_p_y_given_x: -0.0009398040175437927\n",
      "Train acc: 0.82725 | Test acc: 0.8275\n",
      "Epoch: 480\n",
      "Train l_p_x: -7.400773756671697e-05 | Test l_p_x: -6.34000898571685e-05\n",
      "Train l_p_y_given_x: -0.000944499358534813 | Test l_p_y_given_x: -0.0009452490955591202\n",
      "Train acc: 0.8305 | Test acc: 0.83075\n",
      "Epoch: 490\n",
      "Train l_p_x: -5.5068689107429236e-05 | Test l_p_x: -6.144806684460491e-05\n",
      "Train l_p_y_given_x: -0.0009643857032060623 | Test l_p_y_given_x: -0.0009719931483268738\n",
      "Train acc: 0.83425 | Test acc: 0.8345\n",
      "Epoch: 500\n",
      "Train l_p_x: -5.4689142416464165e-05 | Test l_p_x: -6.199626659508795e-05\n",
      "Train l_p_y_given_x: -0.0010009720325469971 | Test l_p_y_given_x: -0.0010088814795017242\n",
      "Train acc: 0.83775 | Test acc: 0.83825\n",
      "Epoch: 510\n",
      "Train l_p_x: -8.485727448714897e-05 | Test l_p_x: -7.439579349011183e-05\n",
      "Train l_p_y_given_x: -0.001068526104092598 | Test l_p_y_given_x: -0.0010576103031635284\n",
      "Train acc: 0.84025 | Test acc: 0.8405\n",
      "Epoch: 520\n",
      "Train l_p_x: -6.176972965477034e-05 | Test l_p_x: -6.346304871840402e-05\n",
      "Train l_p_y_given_x: -0.0011003011912107468 | Test l_p_y_given_x: -0.0010945522338151933\n",
      "Train acc: 0.84275 | Test acc: 0.84275\n",
      "Epoch: 530\n",
      "Train l_p_x: -8.990176138468087e-05 | Test l_p_x: -8.419853838859126e-05\n",
      "Train l_p_y_given_x: -0.0011401931643486023 | Test l_p_y_given_x: -0.0011422351896762848\n",
      "Train acc: 0.8465 | Test acc: 0.84725\n",
      "Epoch: 540\n",
      "Train l_p_x: -6.173690053401515e-05 | Test l_p_x: -7.819405436748639e-05\n",
      "Train l_p_y_given_x: -0.0011606812179088594 | Test l_p_y_given_x: -0.0011814931333065032\n",
      "Train acc: 0.85 | Test acc: 0.85\n",
      "Epoch: 550\n",
      "Train l_p_x: -7.295814430108294e-05 | Test l_p_x: -8.9399101852905e-05\n",
      "Train l_p_y_given_x: -0.0011245740950107574 | Test l_p_y_given_x: -0.0011209867894649505\n",
      "Train acc: 0.85125 | Test acc: 0.85175\n",
      "Epoch: 560\n",
      "Train l_p_x: -6.003043381497264e-05 | Test l_p_x: -8.994591917144135e-05\n",
      "Train l_p_y_given_x: -0.001068725049495697 | Test l_p_y_given_x: -0.001063671037554741\n",
      "Train acc: 0.8545 | Test acc: 0.8545\n",
      "Epoch: 570\n",
      "Train l_p_x: -7.60676630306989e-05 | Test l_p_x: -7.317284325836226e-05\n",
      "Train l_p_y_given_x: -0.0011190406531095506 | Test l_p_y_given_x: -0.0011047528237104415\n",
      "Train acc: 0.857 | Test acc: 0.857\n",
      "Epoch: 580\n",
      "Train l_p_x: -6.517857400467619e-05 | Test l_p_x: -8.681163308210671e-05\n",
      "Train l_p_y_given_x: -0.0011077090799808502 | Test l_p_y_given_x: -0.001142445743083954\n",
      "Train acc: 0.85875 | Test acc: 0.85875\n",
      "Epoch: 590\n",
      "Train l_p_x: -6.738576485076919e-05 | Test l_p_x: -7.004320650594309e-05\n",
      "Train l_p_y_given_x: -0.0011768366992473602 | Test l_p_y_given_x: -0.0011948084831237794\n",
      "Train acc: 0.86275 | Test acc: 0.86275\n",
      "Epoch: 600\n",
      "Train l_p_x: -8.236366556957364e-05 | Test l_p_x: -7.900973287178203e-05\n",
      "Train l_p_y_given_x: -0.0012301658540964126 | Test l_p_y_given_x: -0.0012106359004974364\n",
      "Train acc: 0.8655 | Test acc: 0.8655\n",
      "Epoch: 610\n",
      "Train l_p_x: -7.48182283132337e-05 | Test l_p_x: -6.81434030411765e-05\n",
      "Train l_p_y_given_x: -0.001184560611844063 | Test l_p_y_given_x: -0.0011761122196912764\n",
      "Train acc: 0.868 | Test acc: 0.86825\n",
      "Epoch: 620\n",
      "Train l_p_x: -7.984626427059993e-05 | Test l_p_x: -5.8903726312564686e-05\n",
      "Train l_p_y_given_x: -0.001184896856546402 | Test l_p_y_given_x: -0.001185570999979973\n",
      "Train acc: 0.871 | Test acc: 0.871\n",
      "Epoch: 630\n",
      "Train l_p_x: -7.130775338737294e-05 | Test l_p_x: -7.598074444103986e-05\n",
      "Train l_p_y_given_x: -0.0011744705587625503 | Test l_p_y_given_x: -0.001204647421836853\n",
      "Train acc: 0.87425 | Test acc: 0.87425\n",
      "Epoch: 640\n",
      "Train l_p_x: -7.668373291380703e-05 | Test l_p_x: -8.815775072434917e-05\n",
      "Train l_p_y_given_x: -0.0011547224372625352 | Test l_p_y_given_x: -0.0011443295925855637\n",
      "Train acc: 0.877 | Test acc: 0.877\n",
      "Epoch: 650\n",
      "Train l_p_x: -9.086541103897616e-05 | Test l_p_x: -9.328429587185383e-05\n",
      "Train l_p_y_given_x: -0.0011861724257469176 | Test l_p_y_given_x: -0.001168665200471878\n",
      "Train acc: 0.881 | Test acc: 0.88125\n",
      "Epoch: 660\n",
      "Train l_p_x: -0.00010178393858950585 | Test l_p_x: -9.672651503933594e-05\n",
      "Train l_p_y_given_x: -0.0012139350324869157 | Test l_p_y_given_x: -0.001209175005555153\n",
      "Train acc: 0.88325 | Test acc: 0.8835\n",
      "Epoch: 670\n",
      "Train l_p_x: -7.578565418953076e-05 | Test l_p_x: -3.914761691703461e-05\n",
      "Train l_p_y_given_x: -0.0010407452434301376 | Test l_p_y_given_x: -0.0009921691566705704\n",
      "Train acc: 0.8855 | Test acc: 0.8855\n",
      "Epoch: 680\n",
      "Train l_p_x: -7.216614903882146e-05 | Test l_p_x: -4.688838453148492e-05\n",
      "Train l_p_y_given_x: -0.0011120958924293518 | Test l_p_y_given_x: -0.0010865740180015565\n",
      "Train acc: 0.88775 | Test acc: 0.88775\n",
      "Epoch: 690\n",
      "Train l_p_x: -6.403300358215347e-05 | Test l_p_x: -9.369001054437831e-05\n",
      "Train l_p_y_given_x: -0.0010795715302228928 | Test l_p_y_given_x: -0.0010980365723371505\n",
      "Train acc: 0.89 | Test acc: 0.89025\n",
      "Epoch: 700\n",
      "Train l_p_x: -4.8386038542957976e-05 | Test l_p_x: -4.7398865717696026e-05\n",
      "Train l_p_y_given_x: -0.0010026789903640747 | Test l_p_y_given_x: -0.0009441394954919815\n",
      "Train acc: 0.8915 | Test acc: 0.8915\n",
      "Epoch: 710\n",
      "Train l_p_x: -4.4286625779932365e-05 | Test l_p_x: -3.672981256386265e-05\n",
      "Train l_p_y_given_x: -0.0009904388040304184 | Test l_p_y_given_x: -0.0009929759949445724\n",
      "Train acc: 0.89375 | Test acc: 0.89375\n",
      "Epoch: 720\n",
      "Train l_p_x: -3.812975046457723e-05 | Test l_p_x: -5.0691727665252984e-05\n",
      "Train l_p_y_given_x: -0.0009640017300844193 | Test l_p_y_given_x: -0.0009682404398918152\n",
      "Train acc: 0.89575 | Test acc: 0.89575\n",
      "Epoch: 730\n",
      "Train l_p_x: -4.990694287698716e-05 | Test l_p_x: -3.695598570629954e-05\n",
      "Train l_p_y_given_x: -0.0009767978489398955 | Test l_p_y_given_x: -0.0009109926372766494\n",
      "Train acc: 0.8985 | Test acc: 0.8985\n",
      "Epoch: 740\n",
      "Train l_p_x: -6.9453424657695e-05 | Test l_p_x: -8.806755067780614e-05\n",
      "Train l_p_y_given_x: -0.0008803190737962723 | Test l_p_y_given_x: -0.0009567306488752366\n",
      "Train acc: 0.901 | Test acc: 0.901\n",
      "Epoch: 750\n",
      "Train l_p_x: -7.137808279367164e-05 | Test l_p_x: -5.504814180312678e-05\n",
      "Train l_p_y_given_x: -0.0010168392658233643 | Test l_p_y_given_x: -0.0009075670540332794\n",
      "Train acc: 0.90325 | Test acc: 0.9035\n",
      "Epoch: 760\n",
      "Train l_p_x: -2.8182417736388743e-05 | Test l_p_x: -3.7507117667701095e-05\n",
      "Train l_p_y_given_x: -0.0009465694725513458 | Test l_p_y_given_x: -0.0009290841370821\n",
      "Train acc: 0.90525 | Test acc: 0.90525\n",
      "Epoch: 770\n",
      "Train l_p_x: -6.943482731003314e-05 | Test l_p_x: -7.779693987686187e-05\n",
      "Train l_p_y_given_x: -0.0010480197221040726 | Test l_p_y_given_x: -0.0010151565968990325\n",
      "Train acc: 0.90675 | Test acc: 0.90675\n",
      "Epoch: 780\n",
      "Train l_p_x: -6.640356878051534e-05 | Test l_p_x: -7.256815297296271e-05\n",
      "Train l_p_y_given_x: -0.001037211149930954 | Test l_p_y_given_x: -0.0010769262164831161\n",
      "Train acc: 0.90775 | Test acc: 0.9075\n",
      "Epoch: 790\n",
      "Train l_p_x: -6.500566087197512e-05 | Test l_p_x: -6.49803041596897e-05\n",
      "Train l_p_y_given_x: -0.0010514436364173888 | Test l_p_y_given_x: -0.0010387115180492401\n",
      "Train acc: 0.907 | Test acc: 0.907\n",
      "Epoch: 800\n",
      "Train l_p_x: -6.324837158899754e-05 | Test l_p_x: -7.042643846943974e-05\n",
      "Train l_p_y_given_x: -0.0010967826545238495 | Test l_p_y_given_x: -0.0011250023245811462\n",
      "Train acc: 0.90825 | Test acc: 0.90825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 810\n",
      "Train l_p_x: -7.010424451436847e-05 | Test l_p_x: -5.556306496146135e-05\n",
      "Train l_p_y_given_x: -0.0010206528306007385 | Test l_p_y_given_x: -0.0010582465231418609\n",
      "Train acc: 0.9085 | Test acc: 0.90875\n",
      "Epoch: 820\n",
      "Train l_p_x: -8.935118239605799e-05 | Test l_p_x: -5.076140587334521e-05\n",
      "Train l_p_y_given_x: -0.0009488563239574432 | Test l_p_y_given_x: -0.0009479584097862243\n",
      "Train acc: 0.9105 | Test acc: 0.9105\n",
      "Epoch: 830\n",
      "Train l_p_x: -5.32480189576745e-05 | Test l_p_x: -5.3618583478964865e-05\n",
      "Train l_p_y_given_x: -0.0007855977416038513 | Test l_p_y_given_x: -0.0007262855172157288\n",
      "Train acc: 0.91175 | Test acc: 0.91175\n",
      "Epoch: 840\n",
      "Train l_p_x: -5.650988532579504e-05 | Test l_p_x: -2.910846524173394e-05\n",
      "Train l_p_y_given_x: -0.0006322330832481385 | Test l_p_y_given_x: -0.0005601896047592163\n",
      "Train acc: 0.91375 | Test acc: 0.914\n",
      "Epoch: 850\n",
      "Train l_p_x: -3.740245301742107e-05 | Test l_p_x: -5.901748227188364e-05\n",
      "Train l_p_y_given_x: -0.0005632666349411011 | Test l_p_y_given_x: -0.0005503564476966858\n",
      "Train acc: 0.914 | Test acc: 0.914\n",
      "Epoch: 860\n",
      "Train l_p_x: -2.290102929691784e-05 | Test l_p_x: -1.1245638233958744e-05\n",
      "Train l_p_y_given_x: -0.0005969254672527313 | Test l_p_y_given_x: -0.0006579810380935669\n",
      "Train acc: 0.914 | Test acc: 0.914\n",
      "Epoch: 870\n",
      "Train l_p_x: -3.818086042883806e-05 | Test l_p_x: -4.8810932639753446e-05\n",
      "Train l_p_y_given_x: -0.0008043153285980225 | Test l_p_y_given_x: -0.0007675120234489441\n",
      "Train acc: 0.9145 | Test acc: 0.9145\n",
      "Epoch: 880\n",
      "Train l_p_x: -4.755303598358296e-05 | Test l_p_x: -2.994975511683151e-05\n",
      "Train l_p_y_given_x: -0.0006724514961242676 | Test l_p_y_given_x: -0.0006237832903861999\n",
      "Train acc: 0.9165 | Test acc: 0.9165\n",
      "Epoch: 890\n",
      "Train l_p_x: -2.2306741811917163e-05 | Test l_p_x: -2.1414847651612945e-05\n",
      "Train l_p_y_given_x: -0.0006486616134643555 | Test l_p_y_given_x: -0.0005121994018554688\n",
      "Train acc: 0.919 | Test acc: 0.919\n",
      "Epoch: 900\n",
      "Train l_p_x: -1.2978077393199783e-05 | Test l_p_x: -4.130390516365878e-05\n",
      "Train l_p_y_given_x: -0.0005048430860042573 | Test l_p_y_given_x: -0.00045079964399337766\n",
      "Train acc: 0.92075 | Test acc: 0.92075\n",
      "Epoch: 910\n",
      "Train l_p_x: -3.465965710347518e-05 | Test l_p_x: -5.2727642469108105e-05\n",
      "Train l_p_y_given_x: -0.0004534527063369751 | Test l_p_y_given_x: -0.0005060747265815735\n",
      "Train acc: 0.92225 | Test acc: 0.922\n",
      "Epoch: 920\n",
      "Train l_p_x: -4.857605745200999e-05 | Test l_p_x: -2.7344376576365903e-05\n",
      "Train l_p_y_given_x: -0.000586999386548996 | Test l_p_y_given_x: -0.0005818215608596801\n",
      "Train acc: 0.92375 | Test acc: 0.92375\n",
      "Epoch: 930\n",
      "Train l_p_x: -1.1851340786961373e-05 | Test l_p_x: -3.3092888770624995e-05\n",
      "Train l_p_y_given_x: -0.0006654033660888672 | Test l_p_y_given_x: -0.0007857694625854492\n",
      "Train acc: 0.92425 | Test acc: 0.92425\n",
      "Epoch: 940\n",
      "Train l_p_x: -3.744193963939324e-05 | Test l_p_x: -4.318305946071632e-05\n",
      "Train l_p_y_given_x: -0.0007230969369411468 | Test l_p_y_given_x: -0.0007347487211227417\n",
      "Train acc: 0.92525 | Test acc: 0.92525\n",
      "Epoch: 950\n",
      "Train l_p_x: -5.023563062422909e-05 | Test l_p_x: -7.209795876406133e-05\n",
      "Train l_p_y_given_x: -0.0007745800316333771 | Test l_p_y_given_x: -0.0006891848742961883\n",
      "Train acc: 0.926 | Test acc: 0.926\n",
      "Epoch: 960\n",
      "Train l_p_x: -1.2173056802566862e-06 | Test l_p_x: -6.876167753944173e-05\n",
      "Train l_p_y_given_x: -0.00053988516330719 | Test l_p_y_given_x: -0.0005883806943893432\n",
      "Train acc: 0.9275 | Test acc: 0.9275\n",
      "Epoch: 970\n",
      "Train l_p_x: -4.6140434278640896e-05 | Test l_p_x: -3.530594767653383e-05\n",
      "Train l_p_y_given_x: -0.0006884941458702087 | Test l_p_y_given_x: -0.0005989103615283967\n",
      "Train acc: 0.9275 | Test acc: 0.9275\n",
      "Epoch: 980\n",
      "Train l_p_x: -2.7516127374838106e-05 | Test l_p_x: -3.096994987572543e-05\n",
      "Train l_p_y_given_x: -0.0005117392838001251 | Test l_p_y_given_x: -0.0006083298325538635\n",
      "Train acc: 0.9275 | Test acc: 0.9275\n",
      "Epoch: 990\n",
      "Train l_p_x: -7.383430056506768e-05 | Test l_p_x: -5.280095501802862e-05\n",
      "Train l_p_y_given_x: -0.0006729702949523925 | Test l_p_y_given_x: -0.0006720751523971557\n",
      "Train acc: 0.928 | Test acc: 0.928\n",
      "Epoch: 1000\n",
      "Train l_p_x: -2.6466221243026666e-05 | Test l_p_x: -4.528224599198438e-05\n",
      "Train l_p_y_given_x: -0.0007192135155200958 | Test l_p_y_given_x: -0.0006557802259922027\n",
      "Train acc: 0.928 | Test acc: 0.92775\n",
      "Epoch: 1010\n",
      "Train l_p_x: -6.335151556413621e-05 | Test l_p_x: -2.2019863536115736e-05\n",
      "Train l_p_y_given_x: -0.0005999735891819001 | Test l_p_y_given_x: -0.0004608960747718811\n",
      "Train acc: 0.9285 | Test acc: 0.9285\n",
      "Epoch: 1020\n",
      "Train l_p_x: -5.2223029342712834e-05 | Test l_p_x: -3.608197175708483e-06\n",
      "Train l_p_y_given_x: -0.0005700399875640869 | Test l_p_y_given_x: -0.0004052235782146454\n",
      "Train acc: 0.9295 | Test acc: 0.9295\n",
      "Epoch: 1030\n",
      "Train l_p_x: -4.234412335790694e-05 | Test l_p_x: -2.794212196022272e-05\n",
      "Train l_p_y_given_x: -0.0006330055892467499 | Test l_p_y_given_x: -0.0005507376492023468\n",
      "Train acc: 0.9295 | Test acc: 0.9295\n",
      "Epoch: 1040\n",
      "Train l_p_x: -4.231941784382798e-05 | Test l_p_x: -5.519596015801653e-05\n",
      "Train l_p_y_given_x: -0.00048675033450126646 | Test l_p_y_given_x: -0.00048500001430511474\n",
      "Train acc: 0.93 | Test acc: 0.93\n",
      "Epoch: 1050\n",
      "Train l_p_x: 3.889083927788306e-06 | Test l_p_x: -4.1217001125914976e-05\n",
      "Train l_p_y_given_x: -0.00045382821559906007 | Test l_p_y_given_x: -0.0005216310918331146\n",
      "Train acc: 0.93025 | Test acc: 0.93025\n",
      "Epoch: 1060\n",
      "Train l_p_x: -4.251340214977972e-05 | Test l_p_x: 1.1366159014869481e-05\n",
      "Train l_p_y_given_x: -0.0004975807964801789 | Test l_p_y_given_x: -0.0004504854083061218\n",
      "Train acc: 0.93125 | Test acc: 0.9315\n",
      "Epoch: 1070\n",
      "Train l_p_x: -1.1465669558674563e-05 | Test l_p_x: -4.820359026780352e-05\n",
      "Train l_p_y_given_x: -0.0004290241003036499 | Test l_p_y_given_x: -0.000370920866727829\n",
      "Train acc: 0.93175 | Test acc: 0.93175\n",
      "Epoch: 1080\n",
      "Train l_p_x: -2.759608833002858e-05 | Test l_p_x: -1.2450815347619937e-06\n",
      "Train l_p_y_given_x: -0.00035800543427467346 | Test l_p_y_given_x: -0.00025646352767944334\n",
      "Train acc: 0.933 | Test acc: 0.93325\n",
      "Epoch: 1090\n",
      "Train l_p_x: -4.417124728206545e-05 | Test l_p_x: -7.8202783697634e-06\n",
      "Train l_p_y_given_x: -0.00039727437496185305 | Test l_p_y_given_x: -0.00038389390707015993\n",
      "Train acc: 0.93325 | Test acc: 0.93325\n",
      "Epoch: 1100\n",
      "Train l_p_x: -5.043110650149174e-05 | Test l_p_x: -1.540091761853546e-05\n",
      "Train l_p_y_given_x: -0.0002412634491920471 | Test l_p_y_given_x: -0.0003285708725452423\n",
      "Train acc: 0.9355 | Test acc: 0.9355\n",
      "Epoch: 1110\n",
      "Train l_p_x: -1.567608160257805e-05 | Test l_p_x: 2.1407813619589433e-05\n",
      "Train l_p_y_given_x: -0.00028020814061164857 | Test l_p_y_given_x: -0.00017666947841644287\n",
      "Train acc: 0.93575 | Test acc: 0.93575\n",
      "Epoch: 1120\n",
      "Train l_p_x: -1.0480314813321456e-05 | Test l_p_x: -3.0098797651589848e-05\n",
      "Train l_p_y_given_x: -0.0003320409655570984 | Test l_p_y_given_x: -0.0003620509207248688\n",
      "Train acc: 0.93575 | Test acc: 0.93575\n",
      "Epoch: 1130\n",
      "Train l_p_x: -6.488889539468801e-06 | Test l_p_x: 2.510994818294421e-06\n",
      "Train l_p_y_given_x: -0.00042806020379066465 | Test l_p_y_given_x: -0.00027936753630638123\n",
      "Train acc: 0.93525 | Test acc: 0.9355\n",
      "Epoch: 1140\n",
      "Train l_p_x: -3.591019049054012e-05 | Test l_p_x: -5.963888906990178e-05\n",
      "Train l_p_y_given_x: -0.00042143043875694276 | Test l_p_y_given_x: -0.0003599657714366913\n",
      "Train acc: 0.9355 | Test acc: 0.9355\n",
      "Epoch: 1150\n",
      "Train l_p_x: -5.775305908173323e-05 | Test l_p_x: -1.0501891665626317e-05\n",
      "Train l_p_y_given_x: -0.0003829830288887024 | Test l_p_y_given_x: -0.0003195134699344635\n",
      "Train acc: 0.93625 | Test acc: 0.93625\n",
      "Epoch: 1160\n",
      "Train l_p_x: -9.471297744312324e-06 | Test l_p_x: -4.5488777686841786e-05\n",
      "Train l_p_y_given_x: -0.00043598833680152894 | Test l_p_y_given_x: -0.000635042279958725\n",
      "Train acc: 0.93675 | Test acc: 0.9365\n",
      "Epoch: 1170\n",
      "Train l_p_x: -2.5474519134149887e-05 | Test l_p_x: 1.163750994237489e-06\n",
      "Train l_p_y_given_x: -0.0002722841799259186 | Test l_p_y_given_x: -0.00019061440229415892\n",
      "Train acc: 0.9365 | Test acc: 0.9365\n",
      "Epoch: 1180\n",
      "Train l_p_x: -2.217707151430659e-05 | Test l_p_x: -7.235923840198666e-05\n",
      "Train l_p_y_given_x: -0.0004215782880783081 | Test l_p_y_given_x: -0.000396441787481308\n",
      "Train acc: 0.93675 | Test acc: 0.93675\n",
      "Epoch: 1190\n",
      "Train l_p_x: -3.5422654036665335e-05 | Test l_p_x: -4.0284307033289224e-05\n",
      "Train l_p_y_given_x: -0.000233409583568573 | Test l_p_y_given_x: -0.00028380289673805235\n",
      "Train acc: 0.93675 | Test acc: 0.93675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1200\n",
      "Train l_p_x: -3.7530273402808234e-05 | Test l_p_x: -3.9797516365069896e-05\n",
      "Train l_p_y_given_x: -0.0005254607498645783 | Test l_p_y_given_x: -0.000549724668264389\n",
      "Train acc: 0.93675 | Test acc: 0.9365\n",
      "Epoch: 1210\n",
      "Train l_p_x: -5.516955570783466e-05 | Test l_p_x: -2.23440547415521e-05\n",
      "Train l_p_y_given_x: -0.00029814204573631284 | Test l_p_y_given_x: -0.00030801528692245484\n",
      "Train acc: 0.93675 | Test acc: 0.93675\n",
      "Epoch: 1220\n",
      "Train l_p_x: 1.3333291462913621e-05 | Test l_p_x: -3.2528045267099515e-05\n",
      "Train l_p_y_given_x: -0.0004246940314769745 | Test l_p_y_given_x: -0.00036882930994033814\n",
      "Train acc: 0.93675 | Test acc: 0.93675\n",
      "Epoch: 1230\n",
      "Train l_p_x: -4.789963713847101e-05 | Test l_p_x: -3.0908140615792945e-05\n",
      "Train l_p_y_given_x: -0.0003174860179424286 | Test l_p_y_given_x: -0.00035462507605552675\n",
      "Train acc: 0.93525 | Test acc: 0.93525\n",
      "Epoch: 1240\n",
      "Train l_p_x: -2.9805185477016494e-05 | Test l_p_x: -8.420467565883882e-06\n",
      "Train l_p_y_given_x: -0.00033911576867103575 | Test l_p_y_given_x: -0.0003859597146511078\n",
      "Train acc: 0.935 | Test acc: 0.935\n",
      "Epoch: 1250\n",
      "Train l_p_x: -8.840829650580417e-06 | Test l_p_x: -4.786953650182113e-05\n",
      "Train l_p_y_given_x: -0.0004329167306423187 | Test l_p_y_given_x: -0.0004693182408809662\n",
      "Train acc: 0.93475 | Test acc: 0.935\n",
      "Epoch: 1260\n",
      "Train l_p_x: -1.6321480870828964e-05 | Test l_p_x: 3.336182271596044e-05\n",
      "Train l_p_y_given_x: -0.00033615902066230774 | Test l_p_y_given_x: -7.608404755592346e-05\n",
      "Train acc: 0.935 | Test acc: 0.935\n",
      "Epoch: 1270\n",
      "Train l_p_x: -5.5458160204580054e-05 | Test l_p_x: -3.763601489481516e-05\n",
      "Train l_p_y_given_x: -8.501783013343811e-05 | Test l_p_y_given_x: -0.0002241562306880951\n",
      "Train acc: 0.93475 | Test acc: 0.935\n",
      "Epoch: 1280\n",
      "Train l_p_x: -7.125255797291175e-05 | Test l_p_x: -8.305311894218903e-06\n",
      "Train l_p_y_given_x: -0.0005364960432052612 | Test l_p_y_given_x: -0.00046297708153724673\n",
      "Train acc: 0.93525 | Test acc: 0.93525\n",
      "Epoch: 1290\n",
      "Train l_p_x: -6.950849638087675e-05 | Test l_p_x: -3.657859633676708e-05\n",
      "Train l_p_y_given_x: -0.0004947316348552703 | Test l_p_y_given_x: -0.0005256078243255616\n",
      "Train acc: 0.9345 | Test acc: 0.93475\n",
      "Epoch: 1300\n",
      "Train l_p_x: -2.8051943445461802e-05 | Test l_p_x: 3.7306251670088386e-06\n",
      "Train l_p_y_given_x: -0.0004043504595756531 | Test l_p_y_given_x: -0.00043639308214187624\n",
      "Train acc: 0.935 | Test acc: 0.935\n",
      "Epoch: 1310\n",
      "Train l_p_x: -2.681791920622345e-05 | Test l_p_x: -0.00010733998351497576\n",
      "Train l_p_y_given_x: -0.0004335997402667999 | Test l_p_y_given_x: -0.0006301612555980683\n",
      "Train acc: 0.935 | Test acc: 0.935\n",
      "Epoch: 1320\n",
      "Train l_p_x: 4.169056046521291e-05 | Test l_p_x: 6.521475734189153e-05\n",
      "Train l_p_y_given_x: -0.00012401330471038818 | Test l_p_y_given_x: -8.928725123405457e-05\n",
      "Train acc: 0.93575 | Test acc: 0.9355\n",
      "Epoch: 1330\n",
      "Train l_p_x: -7.477659528376535e-05 | Test l_p_x: -5.2542509365594015e-05\n",
      "Train l_p_y_given_x: -0.0003467539548873901 | Test l_p_y_given_x: -0.0005232485234737396\n",
      "Train acc: 0.93575 | Test acc: 0.93575\n",
      "Epoch: 1340\n",
      "Train l_p_x: 2.949726695078425e-05 | Test l_p_x: -4.661560069507686e-06\n",
      "Train l_p_y_given_x: -0.0009058385789394379 | Test l_p_y_given_x: -0.0007847127914428711\n",
      "Train acc: 0.9355 | Test acc: 0.9355\n",
      "Epoch: 1350\n",
      "Train l_p_x: -1.4546365491696633e-05 | Test l_p_x: -9.510976815363392e-05\n",
      "Train l_p_y_given_x: -0.0004886520802974701 | Test l_p_y_given_x: -0.0004917523264884949\n",
      "Train acc: 0.93525 | Test acc: 0.93525\n",
      "Epoch: 1360\n",
      "Train l_p_x: -3.4036369470413774e-05 | Test l_p_x: -6.073856638977304e-05\n",
      "Train l_p_y_given_x: -0.00036688670516014097 | Test l_p_y_given_x: -0.00047914475202560426\n",
      "Train acc: 0.9355 | Test acc: 0.9355\n",
      "Epoch: 1370\n",
      "Train l_p_x: -2.2354215616360307e-05 | Test l_p_x: -1.3148576726962347e-05\n",
      "Train l_p_y_given_x: -0.0005760958790779114 | Test l_p_y_given_x: -0.0005469708442687988\n",
      "Train acc: 0.93575 | Test acc: 0.93575\n",
      "Epoch: 1380\n",
      "Train l_p_x: -8.756930037634447e-05 | Test l_p_x: -2.8639615266001783e-05\n",
      "Train l_p_y_given_x: -0.0006711293160915375 | Test l_p_y_given_x: -0.0007192161083221435\n",
      "Train acc: 0.9365 | Test acc: 0.9365\n",
      "Epoch: 1390\n",
      "Train l_p_x: -6.444418977480382e-05 | Test l_p_x: -4.0441842429572716e-05\n",
      "Train l_p_y_given_x: -0.0005761322379112244 | Test l_p_y_given_x: -0.000777358740568161\n",
      "Train acc: 0.93625 | Test acc: 0.936\n",
      "Epoch: 1400\n",
      "Train l_p_x: 6.5614585764706135e-06 | Test l_p_x: -5.497664460563101e-05\n",
      "Train l_p_y_given_x: -0.0005919212698936462 | Test l_p_y_given_x: -0.00036457806825637815\n",
      "Train acc: 0.93625 | Test acc: 0.93625\n",
      "Epoch: 1410\n",
      "Train l_p_x: -5.017009607399814e-05 | Test l_p_x: -4.735303082270548e-05\n",
      "Train l_p_y_given_x: -0.0006281130611896515 | Test l_p_y_given_x: -0.0004352369010448456\n",
      "Train acc: 0.93775 | Test acc: 0.9375\n",
      "Epoch: 1420\n",
      "Train l_p_x: -6.423330341931432e-05 | Test l_p_x: -9.624800441088155e-05\n",
      "Train l_p_y_given_x: -0.0007715444266796112 | Test l_p_y_given_x: -0.0008322092890739441\n",
      "Train acc: 0.9375 | Test acc: 0.9375\n",
      "Epoch: 1430\n",
      "Train l_p_x: 9.777981176739559e-05 | Test l_p_x: -1.97166218640632e-06\n",
      "Train l_p_y_given_x: -0.0006921261250972748 | Test l_p_y_given_x: -0.0007348693013191223\n",
      "Train acc: 0.937 | Test acc: 0.937\n",
      "Epoch: 1440\n",
      "Train l_p_x: -1.1428118341427762e-05 | Test l_p_x: -7.26254002074711e-05\n",
      "Train l_p_y_given_x: -0.0006489742398262024 | Test l_p_y_given_x: -0.0007575241029262543\n",
      "Train acc: 0.93675 | Test acc: 0.9365\n",
      "Epoch: 1450\n",
      "Train l_p_x: -2.427393337711692e-05 | Test l_p_x: -2.582341585366521e-05\n",
      "Train l_p_y_given_x: -0.0006657464802265167 | Test l_p_y_given_x: -0.0005691094398498535\n",
      "Train acc: 0.9365 | Test acc: 0.9365\n",
      "Epoch: 1460\n",
      "Train l_p_x: -5.1744045777013525e-05 | Test l_p_x: -9.375721674587112e-06\n",
      "Train l_p_y_given_x: -0.0005578998327255249 | Test l_p_y_given_x: -0.0006888271570205689\n",
      "Train acc: 0.9375 | Test acc: 0.9375\n",
      "Epoch: 1470\n",
      "Train l_p_x: 2.253425191156566e-05 | Test l_p_x: -0.00010302138980478048\n",
      "Train l_p_y_given_x: -0.0006842506527900696 | Test l_p_y_given_x: -0.0008889162242412568\n",
      "Train acc: 0.9385 | Test acc: 0.93825\n",
      "Epoch: 1480\n",
      "Train l_p_x: -2.497101013432257e-05 | Test l_p_x: -3.6165864003123716e-05\n",
      "Train l_p_y_given_x: -0.0007794468402862549 | Test l_p_y_given_x: -0.0006305986344814301\n",
      "Train acc: 0.9385 | Test acc: 0.93875\n",
      "Epoch: 1490\n",
      "Train l_p_x: -3.6635490687331185e-05 | Test l_p_x: 2.278208739880938e-06\n",
      "Train l_p_y_given_x: -0.0006950927674770355 | Test l_p_y_given_x: -0.0007484337985515595\n",
      "Train acc: 0.93875 | Test acc: 0.93875\n",
      "Epoch: 1500\n",
      "Train l_p_x: -3.954023486585356e-05 | Test l_p_x: -9.214491001330316e-06\n",
      "Train l_p_y_given_x: -0.0005992205142974854 | Test l_p_y_given_x: -0.000592724859714508\n",
      "Train acc: 0.939 | Test acc: 0.939\n",
      "Epoch: 1510\n",
      "Train l_p_x: -1.4665157323179301e-05 | Test l_p_x: -5.926561789237894e-05\n",
      "Train l_p_y_given_x: -0.0007078296542167664 | Test l_p_y_given_x: -0.0007185519337654113\n",
      "Train acc: 0.93975 | Test acc: 0.93975\n",
      "Epoch: 1520\n",
      "Train l_p_x: -1.9991279259556904e-05 | Test l_p_x: -2.7645051886793226e-05\n",
      "Train l_p_y_given_x: -0.0006597216725349426 | Test l_p_y_given_x: -0.00081293123960495\n",
      "Train acc: 0.9395 | Test acc: 0.9395\n",
      "Epoch: 1530\n",
      "Train l_p_x: -2.012312506849412e-05 | Test l_p_x: -0.0001323686883552\n",
      "Train l_p_y_given_x: -0.0010820541977882385 | Test l_p_y_given_x: -0.0010249521434307098\n",
      "Train acc: 0.93925 | Test acc: 0.9395\n",
      "Epoch: 1540\n",
      "Train l_p_x: -5.860322926309891e-05 | Test l_p_x: 1.815381801861804e-05\n",
      "Train l_p_y_given_x: -0.0007132501304149628 | Test l_p_y_given_x: -0.0007435775995254517\n",
      "Train acc: 0.94 | Test acc: 0.94\n",
      "Epoch: 1550\n",
      "Train l_p_x: -0.00011487150914035738 | Test l_p_x: -0.0001074967731256038\n",
      "Train l_p_y_given_x: -0.0005105054080486298 | Test l_p_y_given_x: -0.0006167106032371521\n",
      "Train acc: 0.94 | Test acc: 0.94025\n",
      "Epoch: 1560\n",
      "Train l_p_x: -7.919890049379319e-05 | Test l_p_x: -5.8661404182203114e-05\n",
      "Train l_p_y_given_x: -0.0011924181878566742 | Test l_p_y_given_x: -0.0009558871984481812\n",
      "Train acc: 0.94075 | Test acc: 0.94075\n",
      "Epoch: 1570\n",
      "Train l_p_x: -4.295236067264341e-05 | Test l_p_x: -0.00012073943798895925\n",
      "Train l_p_y_given_x: -0.0011230626106262208 | Test l_p_y_given_x: -0.0011400234699249267\n",
      "Train acc: 0.9405 | Test acc: 0.94075\n",
      "Epoch: 1580\n",
      "Train l_p_x: -8.459705713903531e-05 | Test l_p_x: -6.797194509999827e-05\n",
      "Train l_p_y_given_x: -0.0007581786811351776 | Test l_p_y_given_x: -0.0008673625290393829\n",
      "Train acc: 0.94125 | Test acc: 0.94125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1590\n",
      "Train l_p_x: 1.6005576981115155e-05 | Test l_p_x: -0.000185873155714944\n",
      "Train l_p_y_given_x: -0.0008755387961864471 | Test l_p_y_given_x: -0.0007525815963745117\n",
      "Train acc: 0.9415 | Test acc: 0.9415\n",
      "Epoch: 1600\n",
      "Train l_p_x: -7.538864156231284e-05 | Test l_p_x: -7.19752351869829e-05\n",
      "Train l_p_y_given_x: -0.0010487231314182282 | Test l_p_y_given_x: -0.0009579304456710816\n",
      "Train acc: 0.94075 | Test acc: 0.941\n",
      "Epoch: 1610\n",
      "Train l_p_x: -5.272287307889201e-05 | Test l_p_x: -0.00017965487495530397\n",
      "Train l_p_y_given_x: -0.001198848932981491 | Test l_p_y_given_x: -0.0014319255650043488\n",
      "Train acc: 0.941 | Test acc: 0.9405\n",
      "Epoch: 1620\n",
      "Train l_p_x: -2.935564589279238e-05 | Test l_p_x: -4.87137476739008e-05\n",
      "Train l_p_y_given_x: -0.0014371826946735383 | Test l_p_y_given_x: -0.0011963847279548646\n",
      "Train acc: 0.94 | Test acc: 0.93975\n",
      "Epoch: 1630\n",
      "Train l_p_x: -9.999740723287687e-05 | Test l_p_x: -0.0001492865412728861\n",
      "Train l_p_y_given_x: -0.0009220494627952576 | Test l_p_y_given_x: -0.0010815762877464294\n",
      "Train acc: 0.93875 | Test acc: 0.93875\n",
      "Epoch: 1640\n",
      "Train l_p_x: -3.76091011276003e-05 | Test l_p_x: 6.44146857666783e-05\n",
      "Train l_p_y_given_x: -0.0012424378991127015 | Test l_p_y_given_x: -0.0010087907016277313\n",
      "Train acc: 0.9385 | Test acc: 0.9385\n",
      "Epoch: 1650\n",
      "Train l_p_x: 2.386802589171566e-05 | Test l_p_x: -0.00011671138054225594\n",
      "Train l_p_y_given_x: -0.0008651412129402161 | Test l_p_y_given_x: -0.0010786103010177613\n",
      "Train acc: 0.939 | Test acc: 0.939\n",
      "Epoch: 1660\n",
      "Train l_p_x: -1.6216099538723938e-05 | Test l_p_x: -0.00010055208986159414\n",
      "Train l_p_y_given_x: -0.0010725547969341277 | Test l_p_y_given_x: -0.0009202378988265992\n",
      "Train acc: 0.93975 | Test acc: 0.93975\n",
      "Epoch: 1670\n",
      "Train l_p_x: -9.18170262593776e-05 | Test l_p_x: -1.8880844436353073e-05\n",
      "Train l_p_y_given_x: -0.0011450605392456055 | Test l_p_y_given_x: -0.0009107641577720642\n",
      "Train acc: 0.9405 | Test acc: 0.94025\n",
      "Epoch: 1680\n",
      "Train l_p_x: -3.779381586355157e-05 | Test l_p_x: -0.00010742050653789192\n",
      "Train l_p_y_given_x: -0.0016960026919841766 | Test l_p_y_given_x: -0.001683294951915741\n",
      "Train acc: 0.9405 | Test acc: 0.9405\n"
     ]
    }
   ],
   "source": [
    "stat = {\n",
    "    'train':{\n",
    "        'l_p_y_given_x':[],\n",
    "        'l_p_x':[],\n",
    "        'total_loss':[],\n",
    "        'accuracy':[]},\n",
    "    'test':{\n",
    "        'l_p_y_given_x':[],\n",
    "        'l_p_x':[],\n",
    "        'total_loss':[],\n",
    "        'accuracy':[]}\n",
    "}\n",
    "\n",
    "for epoch in range(1, n_epochs+1):  # loop over the dataset multiple times\n",
    "\n",
    "    ########### TRAIN ##############\n",
    "    f.train()\n",
    "    l_p_y_given_x_total = 0.0\n",
    "    l_p_x_total = 0.0\n",
    "    L = 0.0\n",
    "    accuracy = 0.0\n",
    "    \n",
    "    for i, (x_p_d,) in enumerate(train_dataloader, 0):\n",
    "        # line 2\n",
    "        x_p_d = x_p_d.to(device)\n",
    "        x_lab, y_lab = train_dataloader_labeled.__next__()\n",
    "        x_lab, y_lab = x_lab.to(device), y_lab.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # line 3\n",
    "        logits = f(x_lab)\n",
    "        l_p_y_given_x = nn.CrossEntropyLoss()(logits, y_lab)\n",
    "        \n",
    "        # line 4 and 5:\n",
    "        x_q = sample_q(f, replay_buffer)  # sample from log-sumexp\n",
    "        \n",
    "        # line 8: get generative lost\n",
    "        fp_all = f(x_p_d).logsumexp(1)\n",
    "        fq_all = f(x_q).logsumexp(1)\n",
    "        fp = fp_all.mean()\n",
    "        fq = fq_all.mean()\n",
    "        l_p_x = -(fp - fq)\n",
    "        \n",
    "        # line 8: sum all losses\n",
    "        L = l_p_y_given_x + l_p_x\n",
    "        \n",
    "        # line 10: update parameters\n",
    "        L.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # get stats\n",
    "        l_p_x_total+=l_p_x.item()\n",
    "        l_p_y_given_x_total+=l_p_y_given_x.item()\n",
    "        pred = logits.argmax(dim=1, keepdim=True) \n",
    "        accuracy += pred.eq(y_lab.view_as(pred)).sum().item()\n",
    "        \n",
    "    stat['train']['l_p_x'].append(l_p_x/len(train_dataloader.dataset))\n",
    "    stat['train']['l_p_y_given_x'].append(l_p_x_total/len(train_dataloader.dataset))\n",
    "    stat['train']['total_loss'].append(L.item()/len(train_dataloader.dataset))\n",
    "    stat['train']['accuracy'].append(accuracy/len(train_dataloader.dataset))\n",
    "            \n",
    "    ########### VALIDATION ##############\n",
    "    f.eval()\n",
    "    l_p_y_given_x_total = 0.0\n",
    "    l_p_x_total = 0.0\n",
    "    L = 0.0\n",
    "    accuracy = 0.0\n",
    "    \n",
    "    for i, (x_p_d,) in enumerate(train_dataloader, 0):\n",
    "        # line 2\n",
    "        x_p_d = x_p_d.to(device)\n",
    "        x_lab, y_lab = train_dataloader_labeled.__next__()\n",
    "        x_lab, y_lab = x_lab.to(device), y_lab.to(device)\n",
    "\n",
    "        # line 3\n",
    "        logits = f(x_lab)\n",
    "        l_p_y_given_x = nn.CrossEntropyLoss()(logits, y_lab)\n",
    "        \n",
    "        # line 4 and 5:\n",
    "        x_q = sample_q(f, replay_buffer)  # sample from log-sumexp\n",
    "        \n",
    "        # line 8: get generative lost\n",
    "        fp_all = f(x_p_d).logsumexp(1)\n",
    "        fq_all = f(x_q).logsumexp(1)\n",
    "        fp = fp_all.mean()\n",
    "        fq = fq_all.mean()\n",
    "        l_p_x = -(fp - fq)\n",
    "        \n",
    "        # line 8: sum all losses\n",
    "        L = l_p_y_given_x + l_p_x\n",
    "                \n",
    "        # get stats\n",
    "        l_p_x_total+=l_p_x.item()\n",
    "        l_p_y_given_x_total+=l_p_y_given_x.item()\n",
    "        pred = logits.argmax(dim=1, keepdim=True) \n",
    "        accuracy += pred.eq(y_lab.view_as(pred)).sum().item()\n",
    "        \n",
    "    stat['test']['l_p_x'].append(l_p_x/len(train_dataloader.dataset))\n",
    "    stat['test']['l_p_y_given_x'].append(l_p_x_total/len(train_dataloader.dataset))\n",
    "    stat['test']['total_loss'].append(L.item()/len(train_dataloader.dataset))\n",
    "    stat['test']['accuracy'].append(accuracy/len(train_dataloader.dataset))\n",
    "\n",
    "    if epoch % print_freq == 0:\n",
    "\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        print(f\"Train l_p_x: {stat['train']['l_p_x'][-1]} | Test l_p_x: {stat['test']['l_p_x'][-1]}\")\n",
    "        print(f\"Train l_p_y_given_x: {stat['train']['l_p_y_given_x'][-1]} | Test l_p_y_given_x: {stat['test']['l_p_y_given_x'][-1]}\")\n",
    "        print(f\"Train acc: {stat['train']['accuracy'][-1]} | Test acc: {stat['test']['accuracy'][-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, figsize=(15,6))\n",
    "ax[0].plot(stat['train']['l_p_x'], label='l_p_x (Train)')\n",
    "ax[0].plot(stat['test']['l_p_x'], label='l_p_x (Test)')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(stat['train']['l_p_y_given_x'], label='l_p_y_given_x (Train)')\n",
    "ax[1].plot(stat['test']['l_p_y_given_x'], label='l_p_y_given_x (Test)')\n",
    "ax[1].legend()\n",
    "\n",
    "ax[2].plot(stat['train']['total_loss'], label='total_loss (Train)')\n",
    "ax[2].plot(stat['test']['total_loss'], label='total_loss (Test)')\n",
    "ax[2].legend()\n",
    "\n",
    "ax[3].plot(stat['train']['accuracy'], label='accuracy (Train)')\n",
    "ax[3].plot(stat['test']['accuracy'], label='accuracy (Test)')\n",
    "ax[3].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REFINE samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refine\n",
    "def refine_sample(x, D, steps=10, f='KL', eta=0.001, noise_factor=0.0001):\n",
    "    \n",
    "    #f = 'KL'\n",
    "    #eta = 0.001\n",
    "    #noise_factor = 0.0001\n",
    "    \n",
    "    def _velocity(x):\n",
    "        x_t = x.clone()\n",
    "        x_t.requires_grad_(True)\n",
    "        if x_t.grad is not None:\n",
    "            x_t.grad.zero_()\n",
    "        d_score = D(x_t)[:,1]\n",
    "        \n",
    "        # calculate d_score using analytical solution\n",
    "\n",
    "        if f == 'KL':\n",
    "            s = torch.ones_like(d_score.detach())\n",
    "\n",
    "        elif f == 'logD':\n",
    "            s = 1 / (1 + d_score.detach().exp())\n",
    "\n",
    "        elif f == 'JS':\n",
    "            s = 1 / (1 + 1 / d_score.detach().exp())\n",
    "\n",
    "        else:\n",
    "            raise ValueError()\n",
    "\n",
    "        s.expand_as(x_t)\n",
    "        d_score.backward(torch.ones_like(d_score).to(x_t.device))\n",
    "        grad = x_t.grad\n",
    "        return s.data * grad.data\n",
    "    \n",
    "    all_x = [x]\n",
    "    all_v = []\n",
    "    for t in tqdm(range(1, steps + 1), leave=False):\n",
    "        v = _velocity(x)\n",
    "        all_v.append(v.detach())\n",
    "        x = x.data + eta * v +\\\n",
    "            np.sqrt(2*eta) * noise_factor * torch.randn_like(x)\n",
    "        all_x.append(x.detach())\n",
    "    return all_x, all_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_sample = M1.sample([1]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_refinement = 200\n",
    "all_x, all_v = refine_sample(m1_sample, model, steps=steps_refinement, eta=0.15, noise_factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.scatter(m1_samples[:,0], m1_samples[:,1], label='M1', color='r', marker='.', alpha=0.2)\n",
    "ax.scatter(m2_samples[:,0], m2_samples[:,1], label='M2', color='g', marker='.', alpha=0.2)\n",
    "\n",
    "plt.scatter(m1_sample[:, 0], m1_sample[:,1], marker='*', color='b', s=100)\n",
    "for i in range(1, steps_refinement, 20):\n",
    "    plt.scatter(all_x[i][:, 0], all_x[i][:,1], marker='d', color='b', s=4)\n",
    "\n",
    "# ax.set_xlim([-10, 10])\n",
    "# ax.set_ylim([-10, 10])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "all_v_new = torch.vstack(all_v)\n",
    "ax.plot(all_v_new)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
